\begin{thebibliography}{10}

\bibitem{AleksandrovV23}
Andrei Aleksandrov and Kim V{\"{o}}llinger.
\newblock Formalizing piecewise affine activation functions of neural networks
  in coq.
\newblock In Kristin~Yvonne Rozier and Swarat Chaudhuri, editors, {\em {NASA}
  Formal Methods - 15th International Symposium, {NFM} 2023, Houston, TX, USA,
  May 16-18, 2023, Proceedings}, volume 13903 of {\em Lecture Notes in Computer
  Science}, pages 62--78. Springer, 2023.
\newblock \href {https://doi.org/10.1007/978-3-031-33170-1\_4}
  {\path{doi:10.1007/978-3-031-33170-1\_4}}.

\bibitem{aleksandrov2023formalizing}
Andrei Aleksandrov and Kim V{\"o}llinger.
\newblock Formalizing piecewise affine activation functions of neural networks
  in coq.
\newblock In {\em NASA Formal Methods Symposium}, pages 62--78. Springer, 2023.

\bibitem{bagnall2019certifying}
Alexander Bagnall and Gordon Stewart.
\newblock Certifying the true error: Machine learning in coq with verified
  generalization guarantees.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pages 2662--2669, 2019.

\bibitem{brucker2023verifying}
Achim~D Brucker and Amy Stell.
\newblock Verifying feedforward neural networks for classification in
  isabelle/hol.
\newblock In {\em International Symposium on Formal Methods}, pages 427--444.
  Springer, 2023.

\bibitem{chevallier2022constrained}
Mark Chevallier, Matthew Whyte, and Jacques~D Fleuriot.
\newblock Constrained training of neural networks via theorem proving.
\newblock {\em arXiv preprint arXiv:2207.03880}, 2022.

\bibitem{daggitt2023compiling}
Matthew~L Daggitt, Robert Atkey, Wen Kokke, Ekaterina Komendantskaya, and Luca
  Arnaboldi.
\newblock Compiling higher-order specifications to smt solvers: How to deal
  with rejection constructively.
\newblock In {\em Proceedings of the 12th ACM SIGPLAN International Conference
  on Certified Programs and Proofs}, pages 102--120, 2023.

\bibitem{daukantas2021trimming}
Ieva Daukantas, Alessandro Bruni, and Carsten Sch{\"u}rmann.
\newblock Trimming data sets: a verified algorithm for robust mean estimation.
\newblock In {\em 23rd International Symposium on Principles and Practice of
  Declarative Programming}, pages 1--9, 2021.

\bibitem{de2022use}
Elisabetta De~Maria, Abdorrahim Bahrami, Thibaud l’Yvonnet, Amy Felty, Daniel
  Gaff{\'e}, Annie Ressouche, and Franck Grammont.
\newblock On the use of formal methods to model and verify neuronal archetypes.
\newblock {\em Frontiers of Computer Science}, 16(3):1--22, 2022.

\bibitem{easterbrook1998formal}
Steve Easterbrook and John Callahan.
\newblock Formal methods for verification and validation of partial
  specifications: A case study.
\newblock {\em Journal of Systems and Software}, 40(3):199--210, 1998.

\bibitem{einziger2019verifying}
Gil Einziger, Maayan Goldstein, Yaniv Sa’ar, and Itai Segall.
\newblock Verifying robustness of gradient boosted models.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pages 2446--2453, 2019.

\bibitem{katz2019marabou}
Guy Katz, Derek~A Huang, Duligur Ibeling, Kyle Julian, Christopher Lazarus,
  Rachel Lim, Parth Shah, Shantanu Thakoor, Haoze Wu, Aleksandar Zelji{\'c},
  et~al.
\newblock The marabou framework for verification and analysis of deep neural
  networks.
\newblock In {\em Computer Aided Verification: 31st International Conference,
  CAV 2019, New York City, NY, USA, July 15-18, 2019, Proceedings, Part I 31},
  pages 443--452. Springer, 2019.

\bibitem{9842406}
Moez Krichen, Alaeddine Mihoub, Mohammed~Y. Alzahrani, Wilfried Yves~Hamilton
  Adoni, and Tarik Nahhal.
\newblock Are formal methods applicable to machine learning and artificial
  intelligence?
\newblock In {\em 2022 2nd International Conference of Smart Systems and
  Emerging Technologies (SMARTTECH)}, pages 48--53, 2022.
\newblock \href {https://doi.org/10.1109/SMARTTECH54121.2022.00025}
  {\path{doi:10.1109/SMARTTECH54121.2022.00025}}.

\bibitem{murphy2017verified}
Charlie Murphy, Patrick Gray, and Gordon Stewart.
\newblock Verified perceptron convergence theorem.
\newblock In {\em Proceedings of the 1st ACM SIGPLAN International Workshop on
  Machine Learning and Programming Languages}, pages 43--50, 2017.

\bibitem{ranzato2019robustness}
Francesco Ranzato and Marco Zanella.
\newblock Robustness verification of support vector machines.
\newblock In {\em Static Analysis: 26th International Symposium, SAS 2019,
  Porto, Portugal, October 8--11, 2019, Proceedings 26}, pages 271--295.
  Springer, 2019.

\bibitem{mathcomp}
Mathematical~Components Team.
\newblock Mathematical components library, 2007.
\newblock Last stable version: 2.1 (2023).
\newblock URL: \url{https://github.com/math-comp/math-comp}.

\bibitem{urban2021review}
Caterina Urban and Antoine Min{\'e}.
\newblock A review of formal methods applied to machine learning.
\newblock {\em arXiv preprint arXiv:2104.02466}, 2021.

\bibitem{wang2020comprehensive}
Qi~Wang, Yue Ma, Kun Zhao, and Yingjie Tian.
\newblock A comprehensive survey of loss functions in machine learning.
\newblock {\em Annals of Data Science}, pages 1--26, 2020.

\bibitem{xie2023haskell}
Ningning Xie.
\newblock Haskell for choice-based learning (keynote).
\newblock In {\em Proceedings of the 16th ACM SIGPLAN International Haskell
  Symposium}, pages 1--1, 2023.

\end{thebibliography}
